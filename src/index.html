<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Polyhedral Complex Derivation from Piecewise Trilinear Networks">
  <meta name="keywords" content="Polyhedral Complex, Neural Radiance Fields, 3D Mesh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Tropical NeRF</title>
  <script>
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/fontawesome.all.min.css"> -->
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="./static/images/favicon_white.svg" media="(prefers-color-scheme:dark)">
  <link rel="shortcut icon" href="./static/images/favicon_black.svg" media="(prefers-color-scheme:light)">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script type="module" defer src="./static/js/fontawesome.all.min.js"></script>
  <script type="module" src="./static/js/bulma-carousel.min.js"></script>
  <script type="module" src="./static/js/bulma-slider.min.js"></script>
  <script type="module" src="./static/js/index.js"></script>
  <script type="module" src="./static/js/three_main.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://naver-career.gitbook.io/en/positions/ai-ml/generation-research#selected-publications" target="_blank">
      <span class="icon">
          <i class="fas fa-home"></i>
          <!-- <img src="./static/images/naver_ailab.png" class="png-icon"> -->
      </span>
      </a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://ku-cvlab.github.io/3DFuse/" target="_blank">
            3DFuse (ICLR'24)
          </a>
          <a class="navbar-item" href="https://dl.acm.org/doi/10.5555/3618408.3618936" target="_blank">
            InstantPose (ICML'23)
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Polyhedral Complex Derivation from Piecewise Trilinear Networks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="http://wityworks.com" target="_blank">Jin-Hwa Kim</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>NAVER AI Lab,</span>&nbsp;
            <span class="author-block"><sup>2</sup>AI Institute of Seoul National University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2402.10403"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block disabled">
                <a href="javascript:alert('TBA. Stay tuned!');"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body columns has-text-centered">
      <div class="notification is-danger">
        <!-- <button class="delete"></button> -->
      </div>
      <div id="teaser0" class="column"></div>
      <div id="teaser1" class="column"></div>
    </div>
    <h2 class="subtitle has-text-centered">
        Stanford Bunny and Dragon meshes by<br/>our analytical extraction from InstantNGP (Müller et al., 2022)
    </h2>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in visualizing deep neural networks provide insights into their structures and mesh extraction from Continuous Piecewise Affine (CPWA) functions. Meanwhile, developments in neural surface representation learning incorporate non-linear positional encoding, addressing issues like spectral bias; however, this poses challenges in applying mesh extraction techniques based on CPWA functions. Focusing on trilinear interpolating methods as positional encoding, we present theoretical insights and an analytical mesh extraction, <i>showing the transformation of hypersurfaces to flat planes within the trilinear region under the eikonal constraint</i>. Moreover, we introduce a method for approximating intersecting points among three hypersurfaces contributing to broader applications. We empirically validate correctness and parsimony through chamfer distance and efficiency, and angular distance, while examining the correlation between the eikonal loss and the planarity of the hypersurfaces.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">TL;DR</h2>
        <p>Analytical mesh extraction from an SDF's neural surfaces with trilinear-interpolating positional encoding methods (<i>e.g.</i>, InstantNGP) through the eikonal constraint of hypersurface planarity (Theorem 4.5) with the \( \epsilon \)-error toleration technique (Theorem 4.7).
        </p>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Motivation</h2>
        <p>
          Previous works assumed they extract meshes from Continuous Piecewise Affine (CPWA) functions. It implies that the functions have piecewise linearity, <i>i.e.</i>, ReLU neural networks. However, if you use trilinear interpolation for positional encoding, the networks are no longer linear almost everywhere. In Sec. 4.2, we stated that <i>"In a trilinear space, \( \tau \) projects a line to a curve except the lines on the grid. Notably, the diagonal line \( \mathrm{t} = (t,t,t)^\intercal \) where \( t \in [0, 1] \) is projected to a cubic Bézier curve (<i>ref</i>. Proposition A.2)."</i> Here, tricky one is that the intersection of two curved hypersurfaces is not a line, even multiple curved lines can be found. Henceforth, Thales's theorem (Sec. 3.4) is no longer employed for identifying the point of intersection between a curved edge and a curved hypersurface. Notice that we deal with this problem in light of the discovery of flat constraints from the eikonal equation (Thm. 4.5) and the analytical approximation (Thm. 4.7).
        </p>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Main results</h2>
        <article class="message is-info">
          <div class="message-header">
            <p>Theorem 4.5 (Hypersurface and eikonal constraint)</p>
          </div>
          <div class="message-body">
            <i>Let \( \tau(\mathrm{x}; \Theta_\mathrm{x}) \) be a trilinear interpolation function parameterized by \( \Theta_\mathrm{x} \), neighboring features in a cubic grid, for a given coordinate \( \mathrm{x} \).
            A hypersurface \( \tau(\mathrm{x}) = 0 \) is on the two diagonal points \( \tau(\mathrm{x}_0)=\tau(\mathrm{x}_7)=0 \) while \( \tau(\mathrm{x}_{1\dots 6}) \ne 0 \) for the other six points consisting of a cube. Assumed that it satisfies the eikonal constraint \( \|\nabla \tau(\mathrm{x}) \|_2 = 1 \) for all \( \mathrm{x} \in [0, 1]^3 \). Then, the hypersurface of \( \tau(\mathrm{x})=0 \) is a plane.</i>
          </div>
        </article>
        <p>
          <b><i>Proof sketch.</i></b> Since the eikonal equation is first-order partial differential, the eikonal constraint makes hypersurfaces smooth, which is a plane. To be the second derivatives are equal to zero, we can show that \( \tau(\mathrm{x}_1) + \tau(\mathrm{x}_2) + \tau(\mathrm{x}_4) = 0 \), \( \tau(\mathrm{x}_3) + \tau(\mathrm{x}_5) + \tau(\mathrm{x}_6) = 0 \), \( \tau(\mathrm{x}_1) + \tau(\mathrm{x}_6) = 0 \), \( \tau(\mathrm{x}_2) + \tau(\mathrm{x}_5) = 0 \), and \( \tau(\mathrm{x}_3) + \tau(\mathrm{x}_4) = 0 \) are the planary condition for the six points. Notice that 3-bit representations for the integer indices indicate relative positions in a cube. For the derivation, please see the proof in the Appendix A.
        </p>
        <br/>
        <article class="message is-info">
          <div class="message-header">
            <p>Theorem 4.7 (Intersection of two hypersurfaces and a diagonal plane)</p>
          </div>
          <div class="message-body">
            <i>
              \( \def\tnn{\tilde{\nu}} \def\vx{\mathrm{x}} \def\mP{\mathrm{P}} \def\mQ{\mathrm{Q}} \def\mX{\mathrm{X}} \)Let \( \tnn \) be (piece-wise) trilinear networks, \( \tnn_0(\vx)=0 \) and \( \tnn_1(\vx)=0 \) be two hypersurfaces passing two points \( \vx_0 \) and \( \vx_7 \) such that \( \tnn_0(\vx_0)=\tnn_1(\vx_0)=0 \) and \( \tnn_0(\vx_7)=\tnn_1(\vx_7)=0 \),
              \( \mP_i := \tnn_0(\vx_i) \),
              \( \mP_\alpha = \big[\mP_0;~\mP_{1};~\mP_{4};~\mP_{5} \big] \),
              \( \mP_\beta = \big[\mP_2;~\mP_{3};~\mP_{6};~\mP_{7}\big] \), \( \mQ_i := \tnn_1(\vx_i) \), likewise for \( \mQ_\alpha \) and \( \mQ_\beta \), and
              \( \mX = [(1-x)^2;~ x(1-x);~ (1-x)x;~ x^2] \).
              Then, \( x, z \in [0, 1] \) of the intersection point of the two hypersurfaces and a diagonal plane of \( x=z \) is the solution of the following quartic equation:
              \[
                \mX^\intercal \big(
                    \mP_\alpha \mQ_\beta^\intercal
                    -\mP_\beta \mQ_\alpha^\intercal
                    \big) \mX = 0
              \]
              while
              \[
                  y = \frac{\mX^\intercal\mP_\alpha}{\mX^\intercal(\mP_\alpha - \mP_\beta)} \hspace{2em}(\mP_\alpha \neq \mP_\beta).
              \]
            </i>
          </div>
        </article>
        <p>
          <b><i>Proof sketch.</i></b> Thm. 4.7 exactly handles where the eikonal equation doesn't make perfect hyperplanes. First, we observed the characteristics of trilinear hypersurfaces as illustrated in Figure 6 in the Appendix. Among 64 edge scenarios within a trilinear region, a diagonal plane intersects with the hypersurface in nearly all cases. Moreover, we can take advantage of it since we can eliminate one variable by assuming the curved edge lies on the  plane. In this light, Thm. 4.7 used linear algebra to rearrange two trilinear equations to get the results (Eqn. 16 and 17). As we mentioned in the manuscript in the right column of Line 225-235: "the new vertices lie on at least two hypersurfaces, and the new edges exist on the same hypersurface, while the eikonal constraint minimizes any associated error. This error is tolerated by the hyperparameter =1e-4 (Sec. 6.1) as specified in Definition 3.4."
        </p>
          Figure 5 also suggests empirical evidence. Empirically, the flatness error, derived from the proof of Theorem 4.5, is effectively controlled by the learning rate of the eikonal loss. In the experiments, we used 0.01 to give our results, while many other neural implicit surface learning methods were used to exploit a higher learning rate of 0.1 (e.g., Yariv et al., 2023). Note that, in practice, the eikonal loss is only applied to near-surface using clamps (if the target position is obviously far from a surface, ignore it; it is wise since we are concerned with the surfaces, not wanting exact SDFs for all space) for effective learning, which is sufficient to our extraction method.
        </p>
      </div>
    </div>

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div> -->
    <!-- </div> -->
    <!--/ Matting. -->

    <!-- Animation. 
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

    <!--   </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Links</h2>

        <!-- <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div> -->
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Kim2024tropical,
  author = {Kim, Jin-hwa},
  title = {{Polyhedral Complex Derivation from Piecewise Trilinear Networks}},
  url = {http://arxiv.org/abs/2402.10403},
  year = {2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href=" ">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href=" " class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. Powered by <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> theme.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
